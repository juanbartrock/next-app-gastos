# üöÄ Gu√≠a de Deployment - IA en Vercel

> **Aplicaci√≥n**: Sistema de Gesti√≥n de Gastos con IA (FASE 3)
> 
> **Plataforma**: Vercel + Neon PostgreSQL + OpenAI

---

## ‚ö†Ô∏è **CONSIDERACIONES CR√çTICAS**

### **1. L√≠mites de Vercel por Plan**

| Plan | Timeout Funciones | Memoria | Bandwidth | OpenAI Compatible |
|------|------------------|---------|-----------|-------------------|
| **Hobby** | 10s | 1024MB | 100GB | ‚ö†Ô∏è Limitado |
| **Pro** | 60s | 3008MB | 1TB | ‚úÖ Recomendado |
| **Enterprise** | 900s | 3008MB | Ilimitado | ‚úÖ Ideal |

**üö® IMPORTANTE**: Para FASE 3 con IA, se recomienda m√≠nimo **Plan Pro** debido a:
- Timeouts de OpenAI (5-15 segundos)
- Procesamiento de datos complejos
- M√∫ltiples consultas a base de datos

### **2. Configuraci√≥n de Variables de Entorno**

```bash
# Vercel Dashboard -> Project -> Settings -> Environment Variables

# Database
DATABASE_URL=postgresql://...@ep-...-pooler.sa-east-1.aws.neon.tech/neondb?sslmode=require

# Authentication
NEXTAUTH_SECRET=tu-secret-super-seguro-aqui
NEXTAUTH_URL=https://tu-app.vercel.app

# OpenAI (CR√çTICO para FASE 3)
OPENAI_API_KEY=sk-proj-...

# Optional
NEXT_TELEMETRY_DISABLED=1
NODE_ENV=production
```

**‚ö†Ô∏è Verificar**: Que `NEXTAUTH_URL` coincida exactamente con tu dominio de Vercel.

---

## üîß **CONFIGURACI√ìN OPTIMIZADA**

### **1. Timeouts Configurados en vercel.json**

```json
{
  "functions": {
    "src/app/api/ai/**/route.ts": {
      "maxDuration": 30
    },
    "src/app/api/alertas/evaluate/route.ts": {
      "maxDuration": 25
    },
    "src/app/api/alertas/scheduler/route.ts": {
      "maxDuration": 20
    }
  }
}
```

### **2. Headers de Cache para APIs de IA**

```json
{
  "headers": [
    {
      "source": "/api/ai/(.*)",
      "headers": [
        { "key": "Cache-Control", "value": "s-maxage=300, stale-while-revalidate=600" }
      ]
    }
  ]
}
```

### **3. Optimizaci√≥n de Build**

```json
{
  "builds": [
    {
      "src": "package.json",
      "use": "@vercel/next",
      "config": {
        "installCommand": "npm install --legacy-peer-deps",
        "buildCommand": "npx prisma generate && next build"
      }
    }
  ]
}
```

---

## üìä **MONITOREO Y PERFORMANCE**

### **1. M√©tricas a Vigilar**

- **Function Duration**: APIs de IA deben mantenerse <30s
- **Memory Usage**: Picos durante an√°lisis de IA
- **Error Rate**: Especialmente errores de OpenAI
- **Bandwidth**: Respuestas JSON grandes de IA

### **2. Logs Importantes**

```bash
# Vercel Dashboard -> Functions -> Ver logs de:
/api/ai/analizar-patrones
/api/ai/recomendaciones
/api/ai/alertas-predictivas
/api/ai/reporte-inteligente
/api/ai/detectar-anomalias
```

### **3. Alertas Recomendadas**

- Timeout de funciones >25s
- Error rate >5% en APIs de IA
- Uso de memoria >2GB
- Respuestas de OpenAI fallidas

---

## üõ°Ô∏è **SEGURIDAD EN PRODUCCI√ìN**

### **1. Rate Limiting**

```typescript
// Implementar en middleware.ts
export function middleware(request: NextRequest) {
  // Rate limiting para APIs de IA
  if (request.nextUrl.pathname.startsWith('/api/ai')) {
    // M√°ximo 10 requests por minuto por usuario
    return rateLimitCheck(request)
  }
}
```

### **2. Validaci√≥n de Entrada**

```typescript
// En cada API de IA
export async function GET(request: NextRequest) {
  try {
    const session = await getServerSession(options)
    if (!session?.user?.id) {
      return NextResponse.json({ error: 'No autorizado' }, { status: 401 })
    }
    
    // Validaci√≥n adicional de par√°metros
    // ...
  } catch (error) {
    // Log detallado para debugging en Vercel
    console.error('AI API Error:', {
      error: error.message,
      userId: session?.user?.id,
      timestamp: new Date().toISOString()
    })
  }
}
```

### **3. Manejo de Secretos**

- ‚úÖ **OPENAI_API_KEY**: Nunca en c√≥digo, solo en Vercel env vars
- ‚úÖ **DATABASE_URL**: Con connection pooling habilitado
- ‚úÖ **NEXTAUTH_SECRET**: Generar con crypto strong

---

## üìà **OPTIMIZACIONES ESPEC√çFICAS**

### **1. OpenAI Optimizations**

```typescript
// En AIAnalyzer.ts
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  timeout: 25000, // 25s timeout (menor que Vercel)
  maxRetries: 2,   // Reintentos autom√°ticos
})
```

### **2. Database Connection Pooling**

```bash
# En DATABASE_URL, asegurar connection pooling
postgresql://user:pass@host/db?sslmode=require&connection_limit=10&pool_timeout=20
```

### **3. Response Optimization**

```typescript
// Reducir tama√±o de respuestas JSON
return NextResponse.json({
  success: true,
  data: optimizedData,
  // Omitir metadatos innecesarios en producci√≥n
  ...(process.env.NODE_ENV === 'development' && { debug: debugInfo })
})
```

---

## üö® **PROBLEMAS COMUNES Y SOLUCIONES**

### **1. Timeout de Funciones**

**Problema**: Function timeout despu√©s de 10s
```
Error: Function execution timed out
```

**Soluci√≥n**:
- Upgrade a Plan Pro de Vercel
- Configurar `maxDuration: 30` en vercel.json
- Optimizar prompts de OpenAI

### **2. Errores de OpenAI**

**Problema**: Rate limiting o API errors
```
Error: Rate limit exceeded for OpenAI
```

**Soluci√≥n**:
- Implementar exponential backoff
- Cache de resultados temporales
- Manejo de errores robusto

### **3. Memory Limits**

**Problema**: Out of memory durante an√°lisis
```
Error: JavaScript heap out of memory
```

**Soluci√≥n**:
- Limitar datasets a 100 transacciones
- Procesamiento en chunks
- Optimizar consultas Prisma

### **4. Cold Starts**

**Problema**: Primera ejecuci√≥n lenta
```
Function cold start delay
```

**Soluci√≥n**:
- Warmer functions (opcional)
- Optimizar imports
- Lazy loading de dependencias

---

## ‚úÖ **CHECKLIST DE DEPLOYMENT**

### **Pre-Deployment**
- [ ] Variables de entorno configuradas en Vercel
- [ ] `vercel.json` con timeouts optimizados
- [ ] Tests de APIs de IA pasando
- [ ] OpenAI API key v√°lida y con cr√©ditos
- [ ] Neon database accesible desde Vercel

### **Post-Deployment**
- [ ] Verificar `/api/ai/*` endpoints responden
- [ ] Test completo en `/test-fase3`
- [ ] Monitorear logs de funciones
- [ ] Verificar performance de OpenAI
- [ ] Confirmar timeouts no se exceden

### **Monitoring Continuo**
- [ ] Dashboard de Vercel Analytics
- [ ] Logs de errores de OpenAI
- [ ] M√©tricas de uso de IA
- [ ] Performance de base de datos
- [ ] Costos de OpenAI

---

## üí∞ **ESTIMACI√ìN DE COSTOS**

### **Vercel (Plan Pro - $20/mes)**
- Functions: Incluidas hasta l√≠mites
- Bandwidth: 1TB incluido
- ‚úÖ Recomendado para producci√≥n

### **OpenAI (Pay-per-use)**
- GPT-3.5-turbo: ~$0.002/1K tokens
- GPT-4o-mini: ~$0.15/1M tokens
- Estimado: $10-50/mes para uso moderado

### **Neon PostgreSQL**
- Plan gratuito: 3GB storage
- Plan Pro: $19/mes para m√°s storage
- ‚úÖ Plan gratuito suficiente inicialmente

**Total Estimado**: $20-90/mes para aplicaci√≥n completa

---

## üéØ **RECOMENDACIONES FINALES**

### **Para Producci√≥n Inmediata**
1. **Plan Pro de Vercel** (obligatorio para IA)
2. **Monitoring activo** de timeouts y errores
3. **Rate limiting** en APIs de IA
4. **Backup de database** regular

### **Para Escalabilidad**
1. **Implementar cache** de resultados de IA
2. **Queue system** para an√°lisis largos
3. **Horizontal scaling** con edge functions
4. **Analytics** de uso de IA

---

**‚úÖ ¬°La aplicaci√≥n est√° lista para deployment en Vercel con IA!**

La configuraci√≥n actual soporta todas las funcionalidades de FASE 3 con OpenAI, incluyendo an√°lisis de patrones, recomendaciones, alertas predictivas y reportes inteligentes. 